{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f577f046930>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import torch\n",
    "import numpy\n",
    "import sklearn.datasets\n",
    "import torchvision.datasets\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching dataset\n",
    "MNIST_train = torchvision.datasets.MNIST('./', download=True, train=True)\n",
    "MNIST_test = torchvision.datasets.MNIST('./', download=True, train=False)\n",
    "# mnist = sklearn.datasets.fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = MNIST_train.train_data\n",
    "train_labels = MNIST_train.train_labels\n",
    "test_features = MNIST_test.test_data\n",
    "test_labels = MNIST_test.test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(train_features[7, :, :].numpy())\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  38  43 105 255 253 253 253\n",
      "  253 253 174   6   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  43 139 224 226 252 253 252 252 252\n",
      "  252 252 252 158  14   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 178 252 252 252 252 253 252 252 252\n",
      "  252 252 252 252  59   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 109 252 252 230 132 133 132 132 189\n",
      "  252 252 252 252  59   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   4  29  29  24   0   0   0   0  14\n",
      "  226 252 252 172   7   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  85\n",
      "  243 252 252 144   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  88 189\n",
      "  252 252 252  14   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  91 212 247 252\n",
      "  252 252 204   9   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  32 125 193 193 193 253 252 252 252\n",
      "  238 102  28   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  45 222 252 252 252 252 253 252 252 252\n",
      "  177   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  45 223 253 253 253 253 255 253 253 253\n",
      "  253  74   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  31 123  52  44  44  44  44 143 252\n",
      "  252  74   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  15 252\n",
      "  252  74   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  86 252\n",
      "  252  74   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   5  75   9   0   0   0   0   0   0  98 242 252\n",
      "  252  74   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  61 183 252  29   0   0   0   0  18  92 239 252 252\n",
      "  243  65   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 208 252 252 147 134 134 134 134 203 253 252 252 188\n",
      "   83   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 208 252 252 252 252 252 252 252 252 253 230 153   8\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  49 157 252 252 252 252 252 217 207 146  45   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   7 103 235 252 172 103  24   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_features[7, :, :].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(train_features[1, :, :].numpy())\n",
    "print(train_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.numpy()\n",
    "test_features = test_features.numpy()\n",
    "train_labels = train_labels.numpy()\n",
    "test_labels = test_labels.numpy()\n",
    "\n",
    "train_features = train_features.reshape([-1, 28 * 28]).astype(float)\n",
    "test_features = test_features.reshape([-1, 28 * 28]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Всего 10 классов\n",
    "class MnistNet(torch.nn.Module):\n",
    "    def __init__(self, n_hidden_neurons):\n",
    "        super(MnistNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, n_hidden_neurons)\n",
    "        self.ac1 = torch.nn.Sigmoid()\n",
    "        self.fc2 = torch.nn.Linear(n_hidden_neurons, 10) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net = MnistNet(100)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mnist_net.parameters(), lr=1.0e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9127\n",
      "0.9175\n",
      "0.915\n",
      "0.9242\n",
      "0.9239\n",
      "0.9246\n",
      "0.9293\n",
      "0.9271\n",
      "0.9277\n",
      "0.9328\n",
      "0.9284\n",
      "0.9335\n",
      "0.9306\n",
      "0.9376\n",
      "0.937\n",
      "0.9411\n",
      "0.9384\n",
      "0.9425\n",
      "0.9426\n",
      "0.9403\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "for epoch in range(20):\n",
    "    order = random.permutation(train_features.shape[0])\n",
    "    for start_index in range(0, train_features.shape[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_indice = order[start_index:start_index+batch_size]\n",
    "        batch_features = torch.FloatTensor(train_features[batch_indice, :])\n",
    "        batch_labels = torch.LongTensor(train_labels[batch_indice])\n",
    "        \n",
    "        features_var = torch.autograd.Variable(batch_features)\n",
    "        labels_var = torch.autograd.Variable(batch_labels)\n",
    "        \n",
    "        preds_var = mnist_net.forward(features_var)\n",
    "        loss = criterion(preds_var, labels_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    order = random.permutation(test_features.shape[0])\n",
    "    \n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "    for start_index in range(0, test_features.shape[0], batch_size):\n",
    "        batch_indice = order[start_index:start_index+batch_size]\n",
    "        batch_features = torch.FloatTensor(test_features[batch_indice, :])\n",
    "        trues = test_labels[batch_indice]\n",
    "        \n",
    "        features_var = torch.autograd.Variable(batch_features)\n",
    "        \n",
    "        preds = mnist_net.forward(features_var).data.numpy().argmax(axis=1)\n",
    "        \n",
    "#         print preds.shape\n",
    "#         print trues.shape\n",
    "        \n",
    "        all_preds.append(preds)\n",
    "        all_trues.append(trues)\n",
    "        \n",
    "    all_preds = numpy.concatenate(all_preds)\n",
    "    all_trues = numpy.concatenate(all_trues)\n",
    "    \n",
    "    print((all_preds == all_trues).sum() / float(all_trues.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "Подобрать параметры Adam, при котором достигается наибольшая точность модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_net = MnistNet(100)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mnist_net.parameters(), lr=1.0e-4, betas=(0.9,0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8812\n",
      "0.9068\n",
      "0.9163\n",
      "0.9234\n",
      "0.9277\n",
      "0.9321\n",
      "0.9338\n",
      "0.9362\n",
      "0.9379\n",
      "0.9423\n",
      "0.9434\n",
      "0.9451\n",
      "0.9438\n",
      "0.9463\n",
      "0.9477\n",
      "0.95\n",
      "0.9491\n",
      "0.9506\n",
      "0.9488\n",
      "0.9522\n",
      "0.9508\n",
      "0.9516\n",
      "0.9534\n",
      "0.9541\n",
      "0.9542\n",
      "0.9543\n",
      "0.954\n",
      "0.9556\n",
      "0.9548\n",
      "0.9551\n",
      "0.9553\n",
      "0.9554\n",
      "0.9555\n",
      "0.9556\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "mnist_net.train()\n",
    "for epoch in range(70):\n",
    "    order = random.permutation(train_features.shape[0])\n",
    "    mnist_net.eval()\n",
    "    for start_index in range(0, train_features.shape[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_indice = order[start_index:start_index+batch_size]\n",
    "        batch_features = torch.FloatTensor(train_features[batch_indice, :])\n",
    "        batch_labels = torch.LongTensor(train_labels[batch_indice])\n",
    "        \n",
    "        features_var = torch.autograd.Variable(batch_features)\n",
    "        labels_var = torch.autograd.Variable(batch_labels)\n",
    "        \n",
    "        preds_var = mnist_net.forward(features_var)\n",
    "        loss = criterion(preds_var, labels_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    order = random.permutation(test_features.shape[0])\n",
    "    \n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "    for start_index in range(0, test_features.shape[0], batch_size):\n",
    "        batch_indice = order[start_index:start_index+batch_size]\n",
    "        batch_features = torch.FloatTensor(test_features[batch_indice, :])\n",
    "        trues = test_labels[batch_indice]\n",
    "        \n",
    "        features_var = torch.autograd.Variable(batch_features)\n",
    "        \n",
    "        preds = mnist_net.forward(features_var).data.numpy().argmax(axis=1)\n",
    "        \n",
    "#         print preds.shape\n",
    "#         print trues.shape\n",
    "        \n",
    "        all_preds.append(preds)\n",
    "        all_trues.append(trues)\n",
    "        \n",
    "    all_preds = numpy.concatenate(all_preds)\n",
    "    all_trues = numpy.concatenate(all_trues)\n",
    "    \n",
    "    print((all_preds == all_trues).sum() / float(all_trues.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2\n",
    "Сделать обучение такой же модели для CIFAR-10. Модель изменить в зависимости от предпочтений, добавить оптимизатор по вкусу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets\n",
    "# Fetching dataset\n",
    "CIFAR_train = torchvision.datasets.CIFAR10('./', download=True, train=True)\n",
    "CIFAR_test = torchvision.datasets.CIFAR10('./', download=True, train=False)\n",
    "# mnist = sklearn.datasets.fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = CIFAR_train.train_data\n",
    "train_labels = CIFAR_train.train_labels\n",
    "test_features = CIFAR_test.test_data\n",
    "test_labels = CIFAR_test.test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Всего 10 классов\n",
    "class CifarConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CifarConvNet, self).__init__()\n",
    "        self.batch_norm1 = torch.nn.BatchNorm2d(3)\n",
    "        self.conv1 = torch.nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.act1  = torch.nn.ReLU()\n",
    "        self.pool1 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.batch_norm2 = torch.nn.BatchNorm2d(16)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.act2  = torch.nn.ReLU()\n",
    "\n",
    "        self.pool2 = torch.nn.MaxPool2d(2, 2)\n",
    "        self.batch_norm3 = torch.nn.BatchNorm2d(32)\n",
    "        self.conv3 = torch.nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.act3  = torch.nn.ReLU()\n",
    "        \n",
    "        self.batch_norm4 = torch.nn.BatchNorm1d(64*64)\n",
    "        self.fc1   = torch.nn.Linear(64 * 64, 256)\n",
    "        self.act4  = torch.nn.Tanh()\n",
    "        self.batch_norm5 = torch.nn.BatchNorm1d(256)\n",
    "        self.fc2   = torch.nn.Linear(256, 64)\n",
    "        self.act5  = torch.nn.Tanh()\n",
    "        self.batch_norm6 = torch.nn.BatchNorm1d(64)\n",
    "        self.fc3   = torch.nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.act3(x)\n",
    "        \n",
    "        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.batch_norm5(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act5(x)\n",
    "        x = self.batch_norm6(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_net = CifarConvNet()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cifar_net.parameters(), lr=1.0e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.astype(float)\n",
    "test_featrues = test_features.astype(float)\n",
    "\n",
    "train_labels = numpy.array(train_labels)\n",
    "test_labels = numpy.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 32 elements not 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-bebd2391a593>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlabels_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpreds_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-66177b99cf64>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     47\u001b[0m         return F.batch_norm(\n\u001b[1;32m     48\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             self.training or not self.track_running_stats, self.momentum, self.eps)\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1192\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1193\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m     )\n\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 32 elements not 3"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "for epoch in range(100):\n",
    "    order = random.permutation(train_features.shape[0])\n",
    "    \n",
    "    for start_index in range(0, train_features.shape[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_indice = order[start_index:start_index+batch_size]\n",
    "#         print batch_indice\n",
    "        batch_features = train_features[batch_indice, :, :, :]\n",
    "        \n",
    "        batch_features = torch.FloatTensor(batch_features)\n",
    "        batch_labels = torch.LongTensor(train_labels[batch_indice])\n",
    "        \n",
    "        features_var = torch.autograd.Variable(batch_features)\n",
    "        labels_var = torch.autograd.Variable(batch_labels)\n",
    "        \n",
    "        preds_var = cifar_net.forward(features_var)\n",
    "        loss = criterion(preds_var, labels_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    order = random.permutation(test_features.shape[0])\n",
    "    \n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "    for start_index in range(0, test_features.shape[0], batch_size):\n",
    "        batch_indice = order[start_index:start_index+batch_size]\n",
    "        batch_features = test_features[batch_indice, :, :, :].astype(float)\n",
    "        batch_features = torch.FloatTensor(batch_features)\n",
    "        trues = test_labels[batch_indice]\n",
    "        \n",
    "        features_var = torch.autograd.Variable(batch_features)\n",
    "        \n",
    "        preds = cifar_net.forward(features_var).data.numpy().argmax(axis=1)\n",
    "        \n",
    "#         print preds.shape\n",
    "#         print trues.shape\n",
    "        \n",
    "        all_preds.append(preds)\n",
    "        all_trues.append(trues)\n",
    "        \n",
    "    all_preds = numpy.concatenate(all_preds)\n",
    "    all_trues = numpy.concatenate(all_trues)\n",
    "    \n",
    "    print (all_preds == all_trues).sum() / float(all_trues.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
